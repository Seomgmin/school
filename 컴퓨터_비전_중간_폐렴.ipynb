{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/archive.zip"
      ],
      "metadata": {
        "id": "7rbpSjJQIe1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 데이터 경로 설정\n",
        "train_data_dir = '/content/chest_xray/train'\n",
        "val_data_dir = '/content/chest_xray/val'\n",
        "test_data_dir = '/content/chest_xray/test'\n",
        "\n",
        "# 데이터 생성기 설정\n",
        "img_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# 그레이 스케일, 해상도 축소\n",
        "train_datagen = ImageDataGenerator(rescale=1./255) # 훈련 데이터 전처리\n",
        "val_datagen = ImageDataGenerator(rescale=1./255) # 검증 데이터 전처리\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # 테스트 데이터 전처리\n",
        "\n",
        "# 훈련 데이터 설정, 라벨링\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "# 검증 데이터 설정, 라벨링\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary') \n",
        "\n",
        "# 테스트 데이터 설정, 라벨링\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# 전이학습 모델 생성\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3)) # VGG16 모델 로드\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) # 특징 추출\n",
        "x = Dense(256, activation='relu')(x) # 전결합층 추가\n",
        "predictions = Dense(1, activation='sigmoid')(x) # 출력층 추가\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions) # 전이학습 모델 생성\n",
        "\n",
        "\n",
        "# 사전 훈련된 모델 동결\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "epochs = 10\n",
        "steps_per_epoch = 500 // batch_size  # 2개(노말,폐렴) 클래스당 500개씩 사용\n",
        "validation_steps = val_data.samples // batch_size\n",
        "\n",
        "model.fit(\n",
        "    train_data, # 훈련 데이터\n",
        "    steps_per_epoch=steps_per_epoch, # 에포크 당 스텝 수 10\n",
        "    epochs=epochs, # 전체 에포크 수 10\n",
        "    validation_data=val_data, # 검증 데이터\n",
        "    validation_steps=validation_steps) # 검증 단계 수\n",
        "\n",
        "# 미세조정\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_data, \n",
        "    steps_per_epoch=steps_per_epoch, \n",
        "    epochs=epochs,\n",
        "    validation_data=val_data, \n",
        "    validation_steps=validation_steps) \n",
        "\n",
        "# 모델 평가 \n",
        "test_loss, test_accuracy = model.evaluate(test_data) \n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG9TSWq3QOb2",
        "outputId": "595b672b-09a9-4e5b-fe92-37c7e76d6972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 8s 452ms/step - loss: 0.5271 - accuracy: 0.7312\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 6s 385ms/step - loss: 0.4200 - accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 7s 465ms/step - loss: 0.3370 - accuracy: 0.8479\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 6s 421ms/step - loss: 0.2916 - accuracy: 0.8896\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 6s 364ms/step - loss: 0.2214 - accuracy: 0.9083\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.2394 - accuracy: 0.8958\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 6s 428ms/step - loss: 0.2375 - accuracy: 0.8938\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 6s 369ms/step - loss: 0.2134 - accuracy: 0.9229\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 6s 359ms/step - loss: 0.1806 - accuracy: 0.9354\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 7s 433ms/step - loss: 0.1977 - accuracy: 0.9187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 10s 478ms/step - loss: 2.0459 - accuracy: 0.7479\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.5461 - accuracy: 0.7208\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 7s 479ms/step - loss: 0.5739 - accuracy: 0.7396\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.3308 - accuracy: 0.7437\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 8s 522ms/step - loss: 0.3092 - accuracy: 0.8188\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.2702 - accuracy: 0.9021\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 8s 500ms/step - loss: 0.2917 - accuracy: 0.8729\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 6s 425ms/step - loss: 0.3015 - accuracy: 0.8917\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 7s 420ms/step - loss: 0.2718 - accuracy: 0.8979\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.2444 - accuracy: 0.9250\n",
            "20/20 [==============================] - 7s 311ms/step - loss: 1.1039 - accuracy: 0.7131\n",
            "Test Loss: 1.1039328575134277\n",
            "Test Accuracy: 0.7131410241127014\n"
          ]
        }
      ]
    }
  ]
}